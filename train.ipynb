{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from model import ModelLoader\n",
        "from data import get_data_dirs\n",
        "\n",
        "def save_history(history, fname):\n",
        "\n",
        "    h_df = pd.DataFrame(history.history)\n",
        "    h_df.to_csv(\"./output/logs/history_{}.csv\".format(fname))\n",
        "    print(history)\n",
        "\n",
        "    loss = history.history['loss']\n",
        "    acc = history.history['acc']\n",
        "    val_loss = history.history['val_loss']\n",
        "    val_acc = history.history['val_acc']\n",
        "    nb_epoch = len(acc)\n",
        "\n",
        "    return\n",
        "\n",
        "    # with open(os.path.join(\"/Users/benja/code/jester/result\", 'result_{}.txt'.format(name)), 'w') as fp:\n",
        "    #     fp.write('epoch\\tloss\\tacc\\tval_loss\\tval_acc\\n')\n",
        "    #     for i in range(nb_epoch):\n",
        "    #         fp.write('{}\\t{}\\t{}\\t{}\\t{}\\n'.format(\n",
        "    #             i, loss[i], acc[i], val_loss[i], val_acc[i]))\n",
        "\n",
        "\n",
        "def plot_history(hist_df, fname='train_history.png'):\n",
        "\n",
        "    acc = hist_df['acc']\n",
        "    val_acc = hist_df['val_acc']\n",
        "    loss = hist_df['loss']\n",
        "    val_loss = hist_df['val_loss']\n",
        "\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.savefig(fname)\n",
        "    return\n",
        "\n",
        "\n",
        "labels_want = ['alien', 'devil', 'ghost', 'hearteyes', 'human',\n",
        "               'lipstick', 'octopus', 'poop', 'robot', 'rocket', 'unicorn']\n",
        "\n",
        "def train(model_name, dataset_name):\n",
        "\n",
        "    #: Data parameters\n",
        "    data_dir = get_data_dirs(dataset_name)\n",
        "    n_images = {'train': 400, 'validation': 50, 'test': 50}\n",
        "    image_size = (320, 240)\n",
        "\n",
        "    #: Training parameters\n",
        "    n_epochs = 10\n",
        "    batch_size = 10\n",
        "    steps_per_epoch = n_images['train'] // batch_size #// n_epochs\n",
        "    \n",
        "    #: Load data generators\n",
        "    \n",
        "    # train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1. / 255,\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    class_mode = 'categorical'\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        data_dir['train'],\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=class_mode,\n",
        "        save_to_dir='./images/keras_train'\n",
        "        )\n",
        "\n",
        "    validation_generator = test_datagen.flow_from_directory(\n",
        "        data_dir['validation'],\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=class_mode)\n",
        "\n",
        "\n",
        "    #: Load model\n",
        "    n_labels = len(labels_want)\n",
        "    ml = ModelLoader(n_labels=n_labels, model_name=model_name,\n",
        "                     image_size=image_size)\n",
        "    model = ml.model\n",
        "\n",
        "    #: Define callbacks\n",
        "    checkpointer = ModelCheckpoint(\n",
        "        filepath='./output/hdf5/{}'.format(model_name) +\n",
        "        '-{epoch:03d}-{loss:.3f}.hdf5',\n",
        "        verbose=1,\n",
        "        save_best_only=True)\n",
        "\n",
        "    callbacks = [checkpointer]\n",
        "\n",
        "    #: Training\n",
        "    print('Starting training')\n",
        "\n",
        "    history = model.fit_generator(\n",
        "        generator=train_generator,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=n_epochs,\n",
        "        verbose=1,\n",
        "        callbacks=callbacks,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=10\n",
        "    )\n",
        "\n",
        "    model.save('./output/{}.h5'.format(model_name))\n",
        "    save_history(history, \"hist_{}\".format(model_name))\n",
        "    return history\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "\n",
        "    # model_name = 'vgg16_v0'\n",
        "    # dataset_name = 'robot_human'\n",
        "\n",
        "    model_name = 'simple_cnn_multi'\n",
        "    dataset_name = 'all_multiclass'\n",
        "\n",
        "    history = train(model_name, dataset_name)\n",
        "    h_df = pd.DataFrame(history.history)\n",
        "    h_df.to_csv()\n",
        "    # h_df = pd.read_csv('./output-aws/logs/history_hist_small_binary_cnn_v0.csv')\n",
        "\n",
        "    # plot_history(h_df, fname='cnn_multi_h_r.png')\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}