# cozmo-emoji-bingo 


## Table of Contents
1. [About Cozmo](#about-cozmo)
2. [Playng Bingo with Robot](#playing-bingo-with-robot)
3. [Generating Data for Emoji Classification](#generating-data-for-emoji-classification)
    * [Image Data Recording](#image-data-recording)
    * [Image Data Preprocessing and Augmentation](#image-data-preprocessing-and-augmenation)
4. [Deep Learning for Computer Vision](#deep-learning-for-computer-vision)
    * [Model Architecture](#model-architecture)
    * [Training the Model](#training-the-model)  
    * [Patch Selection](#patch-selection)
    * [Results](#results)
5. [Future Directions](#future-directions)

## About Cozmo
Cozmo is super awesome.
And he is cute.
Lorem Ipsum

## Playng Bingo with Robot
Bingo is such fun. More detail will follow soon
## ğŸ¤– vs ğŸ§” 

## Generating Data for Emoji Classification

Getting enough training data is very important for a good deep learning project. Instead of using generic image datasets, I decided to generate image data as Cozmo would see it. 

With a very simple setup, I displayed imogee on iPad, while cozmo was runnin around it and making pictures of the screen. This helped to get shots from different angles as it is expected that Cozmo can have multiple positions during the game.

![finder](assets/cozmo-dataset.gif)

After collecting images of from Cozmo's camera, I got around 5000 images for all ten classes. Every emogi was displayed on two different backgrounds (black and white).

### Image Data Preprocessing and Augmentation

All images then split into three sets of training, validation and test in **60:20:20** ratio. 
Each set further split into ten subsets of all emojee names correspond to ten classes:
# ğŸ‘½ ğŸ˜ˆ ğŸ‘» ğŸ˜ ğŸ§” ğŸ’„ ğŸ™ ğŸ’© ğŸš€ ğŸ¤– ğŸ˜

With Cozmo's on-board camera each image is 320 by 240 pixels.
I chose to use black and white images to make model less computational intensive and training easier.

Next, each image was converted to numpy array and was rescaled to 1/255.
To mitigate some early overfit problems, I used Keras Image generator to augment training images. 
Thhis will help to improe the results although, augmentated images can still be highly correlated. Below is an is a batch of images, generated by augmenting image from training set.

**Image recorded by Cozmo**:

![finder](assets/img-camera.png)

**Images generated by Keras:**

![finder](assets/img-keras.png)

Augmentation settings:

```python
train_datagen = ImageDataGenerator(
        rescale=1. / 255,
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest')
```

## Deep Learning for Computer Vision

Convolutional Neural Networks a crucial algrorithm of deep learning. And one of the \


### Convnet Architecture

### Model Training and Evaluation

Some Accuracy plots:

![finder](assets/val-acc-5cl-noaugm.png)
Data Augmentation: YesNo
Train-Validation-Test split: 30:10:10
Number of classes: 5


![finder](assets/val-acc-5cl-augm.png)

Data Augmentation: Yes
Train-Validation-Test split: 30:10:10
Number of classes: 5

## Model Deployment and 
## Demo
##Conclusion and Future Work



